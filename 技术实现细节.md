# LLM安全防护系统技术实现细节

## 📋 目录
1. [核心技术选型](#核心技术选型)
2. [llm-guard集成详解](#llm-guard集成详解)
3. [敏感词处理机制](#敏感词处理机制)
4. [API客户端实现](#api客户端实现)
5. [性能优化技术](#性能优化技术)
6. [安全机制实现](#安全机制实现)

## 🛠️ 核心技术选型

### 技术栈分析

#### 1. llm-guard - 敏感词检测核心
**选择理由**:
- 专业的LLM安全防护库
- 高性能的字符串匹配算法
- 丰富的配置选项
- 活跃的开源社区

**核心特性**:
```python
from llm_guard.input_scanners import BanSubstrings
from llm_guard.input_scanners.ban_substrings import MatchType

# 支持两种匹配模式
MatchType.STR   # 字符串级别匹配（更严格）
MatchType.WORD  # 单词级别匹配（较宽松）
```

#### 2. OpenAI SDK - API客户端基础
**选择理由**:
- 通义千问API兼容OpenAI格式
- 成熟的错误处理机制
- 支持流式和非流式响应
- 完善的类型提示

**实现示例**:
```python
from openai import OpenAI

client = OpenAI(
    api_key="your_qwen_api_key",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)
```

#### 3. pandas - 数据处理
**选择理由**:
- 高效的Excel文件读取
- 强大的数据清洗功能
- 内存优化的数据处理

**使用场景**:
```python
import pandas as pd

# 从Excel提取敏感词
df = pd.read_excel('（4）拦截关键词列表.xlsx')
sensitive_words = df['关键词'].dropna().tolist()
```

## 🔍 llm-guard集成详解

### BanSubstrings扫描器原理

#### 1. 初始化过程
```python
class SensitiveWordDetector:
    def __init__(self, sensitive_words_file, match_type, case_sensitive, redact):
        # 加载敏感词列表
        self.sensitive_words = self._load_sensitive_words()
        
        # 创建BanSubstrings扫描器
        self.scanner = BanSubstrings(
            substrings=self.sensitive_words,      # 敏感词列表
            match_type=self.match_type,           # 匹配类型
            case_sensitive=self.case_sensitive,   # 大小写敏感
            redact=self.redact,                   # 是否替换
            contains_all=self.contains_all        # 是否需要包含所有词
        )
```

#### 2. 扫描算法实现
```python
def scan(self, text: str) -> Tuple[str, bool, float]:
    """
    扫描文本中的敏感词
    
    Returns:
        Tuple[str, bool, float]: (处理后文本, 是否安全, 风险评分)
    """
    if not text:
        return text, True, 0.0
    
    try:
        # 调用llm-guard的核心扫描逻辑
        sanitized_text, is_valid, risk_score = self.scanner.scan(text)
        
        # 记录检测结果
        if not is_valid:
            logger.warning(f"检测到敏感词，风险评分: {risk_score}")
        
        return sanitized_text, is_valid, risk_score
        
    except Exception as e:
        logger.error(f"敏感词扫描失败: {e}")
        # 安全优先：失败时认为不安全
        return text, False, 1.0
```

#### 3. 匹配类型对比

**字符串级别匹配 (MatchType.STR)**:
```python
# 示例文本: "这是一个测试内容"
# 敏感词: "测试"
# 结果: 匹配成功 → "这是一个[REDACT]内容"

# 优点: 检测更全面，不会遗漏
# 缺点: 可能产生误报
```

**单词级别匹配 (MatchType.WORD)**:
```python
# 示例文本: "这是一个测试内容"  
# 敏感词: "测试"
# 结果: 需要完整单词匹配

# 优点: 减少误报
# 缺点: 可能遗漏某些情况
```

### 风险评分机制

#### llm-guard内部评分逻辑
```python
def calculate_risk_score(matches, text_length):
    """
    风险评分计算
    """
    if not matches:
        return -1.0  # 安全标记
    
    # 基于匹配情况计算风险
    if len(matches) > 0:
        return 1.0   # 高风险
    
    return 0.0       # 中等风险
```

## 📝 敏感词处理机制

### 敏感词加载优化

#### 1. 文件读取优化
```python
def _load_sensitive_words(self) -> List[str]:
    """
    优化的敏感词加载
    """
    if not os.path.exists(self.sensitive_words_file):
        logger.error(f"敏感词文件不存在: {self.sensitive_words_file}")
        return []
    
    try:
        # 使用生成器减少内存占用
        words = []
        with open(self.sensitive_words_file, 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip()
                if word and len(word) > 1:  # 过滤无效词汇
                    words.append(word)
        
        # 去重和排序
        words = sorted(list(set(words)))
        logger.info(f"成功加载 {len(words)} 个敏感词")
        return words
        
    except Exception as e:
        logger.error(f"加载敏感词文件失败: {e}")
        return []
```

#### 2. 动态敏感词管理
```python
def add_sensitive_words(self, words: List[str]) -> None:
    """
    动态添加敏感词
    """
    # 验证输入
    valid_words = [word.strip() for word in words if word.strip()]
    
    # 添加到现有列表
    self.sensitive_words.extend(valid_words)
    
    # 重新初始化扫描器
    self.scanner = BanSubstrings(
        substrings=self.sensitive_words,
        match_type=self.match_type,
        case_sensitive=self.case_sensitive,
        redact=self.redact,
        contains_all=self.contains_all
    )
    
    logger.info(f"添加了 {len(valid_words)} 个敏感词，当前总数: {len(self.sensitive_words)}")
```

## 🌐 API客户端实现

### 通义千问API适配

#### 1. 请求格式适配
```python
class QwenAPIClient:
    def chat_completion(self, messages: List[Dict[str, str]], **kwargs) -> Dict[str, Any]:
        """
        适配通义千问API格式
        """
        # 构建请求参数
        params = {
            "model": self.model,
            "messages": messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            **kwargs
        }
        
        logger.debug(f"发送API请求: {params}")
        
        try:
            # 调用API
            response = self.client.chat.completions.create(**params)
            
            # 转换响应格式
            return self._format_response(response)
            
        except Exception as e:
            logger.error(f"API调用失败: {e}")
            raise
```

#### 2. 错误处理和重试机制
```python
def robust_api_call(self, messages, max_retries=3):
    """
    健壮的API调用
    """
    for attempt in range(max_retries):
        try:
            return self.chat_completion(messages)
            
        except openai.RateLimitError as e:
            # 限流错误 - 等待后重试
            wait_time = 2 ** attempt  # 指数退避
            logger.warning(f"API限流，等待 {wait_time} 秒后重试")
            time.sleep(wait_time)
            
        except openai.APIError as e:
            # API错误 - 记录并重试
            logger.error(f"API错误 (尝试 {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise
                
        except Exception as e:
            # 其他错误 - 直接抛出
            logger.error(f"未知API错误: {e}")
            raise
    
    raise Exception("API调用失败，已达到最大重试次数")
```

## ⚡ 性能优化技术

### 1. 敏感词检测优化
```python
class OptimizedDetector:
    def __init__(self):
        # 预编译正则表达式
        self._compiled_patterns = {}
        
        # 缓存检测结果
        self._cache = {}
        self._cache_size = 1000
    
    def scan_with_cache(self, text: str):
        """
        带缓存的扫描
        """
        # 计算文本哈希
        text_hash = hash(text)
        
        # 检查缓存
        if text_hash in self._cache:
            return self._cache[text_hash]
        
        # 执行扫描
        result = self.scanner.scan(text)
        
        # 更新缓存
        if len(self._cache) >= self._cache_size:
            # 清理最旧的缓存
            oldest_key = next(iter(self._cache))
            del self._cache[oldest_key]
        
        self._cache[text_hash] = result
        return result
```

### 2. 批量处理优化
```python
def batch_scan(self, texts: List[str]) -> List[Tuple[str, bool, float]]:
    """
    批量扫描文本
    """
    results = []
    
    # 并行处理
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(self.scan, text) for text in texts]
        
        for future in as_completed(futures):
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                logger.error(f"批量扫描失败: {e}")
                results.append((text, False, 1.0))
    
    return results
```

## 🔒 安全机制实现

### 1. 输入验证
```python
def validate_input(self, text: str) -> bool:
    """
    输入验证
    """
    # 长度检查
    if len(text) > 10000:
        logger.warning("输入文本过长")
        return False
    
    # 编码检查
    try:
        text.encode('utf-8')
    except UnicodeEncodeError:
        logger.warning("输入包含无效字符")
        return False
    
    # 格式检查
    if not isinstance(text, str):
        logger.warning("输入类型错误")
        return False
    
    return True
```

### 2. 安全日志
```python
class SecurityLogger:
    def __init__(self):
        self.security_logger = logging.getLogger('security')
        handler = logging.FileHandler('security.log')
        formatter = logging.Formatter(
            '%(asctime)s - SECURITY - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.security_logger.addHandler(handler)
    
    def log_security_event(self, event_type: str, details: dict):
        """
        记录安全事件
        """
        log_entry = {
            'event_type': event_type,
            'timestamp': datetime.now().isoformat(),
            'details': details
        }
        
        self.security_logger.warning(json.dumps(log_entry, ensure_ascii=False))
```

---

通过这些技术实现细节，您可以深入了解系统的核心技术原理和优化策略。这个系统采用了多项先进技术，确保在提供强大功能的同时保持高性能和安全性。

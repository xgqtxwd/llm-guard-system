# LLM安全防护系统使用指南

## 🎯 项目概述

基于开源库llm-guard实现的敏感词检测和模型输出限制系统，专门为通义千问API设计，包含21930+中文敏感词库。

## 📁 项目结构

```
llm-guard/
├── main.py                    # 主程序入口
├── sensitive_word_detector.py # 敏感词检测模块
├── llm_api_client.py         # LLM API客户端
├── demo.py                   # 演示程序
├── test_llm_guard.py         # 测试用例
├── config.json               # 配置文件
├── .env                      # 环境变量
├── requirements.txt          # 依赖列表
├── sensitive_words.txt       # 敏感词列表(21930个)
├── README.md                 # 详细文档
└── 使用指南.md               # 本文件
```

## 🚀 快速开始

### 1. 安装依赖
```bash
pip install llm-guard openai python-dotenv
```

### 2. 配置API密钥
编辑 `config.json` 文件中的API密钥：
```json
{
  "api_client": {
    "api_key": "your_api_key_here",
    "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "model": "qwen-plus"
  }
}
```

### 3. 运行程序

#### 交互模式
```bash
python main.py --interactive
```

#### 直接处理文本
```bash
python main.py --input "您要检测的文本"
```

#### 运行演示
```bash
python demo.py
```

#### 运行测试
```bash
python test_llm_guard.py
```

## 🔧 核心功能

### 1. 敏感词检测
- ✅ 支持21930+中文敏感词
- ✅ 基于llm-guard的BanSubstrings扫描器
- ✅ 支持字符串级别和单词级别匹配
- ✅ 自动用[REDACT]替换敏感词
- ✅ 风险评分机制

### 2. 模型API集成
- ✅ 完整支持通义千问API
- ✅ 兼容OpenAI API格式
- ✅ 支持流式和非流式响应
- ✅ 自动错误处理和重试

### 3. 安全防护
- ✅ 输入输出双重检查
- ✅ 实时风险评分
- ✅ 详细日志记录
- ✅ 灵活配置选项

## 📊 使用示例

### Python API调用

```python
from main import LLMGuardSystem

# 初始化系统
system = LLMGuardSystem("config.json")

# 处理用户请求
result = system.process_request("用户输入的文本")

# 查看结果
print(f"回复: {result['response']}")
print(f"输入安全: {result['input_safe']}")
print(f"输出安全: {result['output_safe']}")
print(f"风险评分: {result['input_risk_score']}")
```

### 敏感词检测

```python
from sensitive_word_detector import create_detector

# 创建检测器
detector = create_detector()

# 检测文本
text = "待检测的文本内容"
sanitized, is_safe, risk_score = detector.scan(text)

print(f"原文: {text}")
print(f"安全: {is_safe}")
print(f"风险评分: {risk_score}")
print(f"处理后: {sanitized}")
```

## ⚙️ 配置说明

### 敏感词检测配置
```json
{
  "sensitive_detector": {
    "sensitive_words_file": "sensitive_words.txt",
    "match_type": "str",           // "str" 或 "word"
    "case_sensitive": false,       // 是否区分大小写
    "redact": true,               // 是否替换敏感词
    "contains_all": false         // 是否需要包含所有敏感词
  }
}
```

### API客户端配置
```json
{
  "api_client": {
    "api_key": "your_api_key",
    "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "model": "qwen-plus",
    "max_tokens": 2000,
    "temperature": 0.7
  }
}
```

### 安全策略配置
```json
{
  "safety": {
    "check_input": true,          // 是否检查输入
    "check_output": true,         // 是否检查输出
    "log_blocked_requests": true  // 是否记录被阻止的请求
  }
}
```

## 🔍 监控和日志

### 日志文件
- 位置: `llm_guard.log`
- 包含: API调用、敏感词检测、安全事件
- 格式: 时间戳 - 模块 - 级别 - 消息

### 监控指标
- 敏感词检测次数
- API调用统计
- 被阻止的请求
- 风险评分分布

## 🛠️ 自定义扩展

### 添加自定义敏感词
```python
# 方法1: 编辑sensitive_words.txt文件
# 每行一个敏感词

# 方法2: 程序中动态添加
detector.add_sensitive_words(["新敏感词1", "新敏感词2"])
```

### 自定义API客户端
```python
from llm_api_client import QwenAPIClient

# 创建自定义客户端
client = QwenAPIClient(
    api_key="your_key",
    model="qwen-turbo",
    temperature=0.5
)
```

## 🚨 常见问题

### Q: 如何调整敏感词检测的严格程度？
A: 修改配置文件中的 `match_type` 参数：
- `"str"`: 字符串级别匹配（更严格）
- `"word"`: 单词级别匹配（较宽松）

### Q: 如何处理误报？
A: 
1. 检查敏感词列表，移除误报词汇
2. 调整 `match_type` 为 "word" 模式
3. 设置 `case_sensitive` 为 true 提高精确度

### Q: 如何提高检测性能？
A: 
1. 减少敏感词数量
2. 使用更精确的匹配模式
3. 调整 `contains_all` 参数

### Q: 支持其他语言模型吗？
A: 当前主要支持通义千问，但可以扩展支持其他OpenAI兼容的API。

## 📈 性能优化建议

1. **敏感词优化**: 定期清理无效敏感词
2. **缓存机制**: 对常见查询结果进行缓存
3. **批量处理**: 使用批量API调用减少延迟
4. **异步处理**: 对于大量请求使用异步处理

## 🔒 安全最佳实践

1. **API密钥管理**: 使用环境变量存储敏感信息
2. **访问控制**: 限制API访问权限
3. **日志安全**: 避免在日志中记录敏感信息
4. **定期更新**: 及时更新敏感词库和依赖

## 📞 技术支持

如有问题或建议，请：
1. 查看 `README.md` 详细文档
2. 运行 `python test_llm_guard.py` 进行自检
3. 查看 `llm_guard.log` 日志文件
4. 通过GitHub Issues联系我们

---

**版本**: 1.0.0  
**更新时间**: 2025-07-14  
**兼容性**: Python 3.8+, llm-guard 0.3.0+

# LLMå®‰å…¨é˜²æŠ¤ç³»ç»Ÿå·¥ä½œæµç¨‹è¯¦è§£

## ğŸ“‹ ç›®å½•
1. [ç³»ç»Ÿå¯åŠ¨æµç¨‹](#ç³»ç»Ÿå¯åŠ¨æµç¨‹)
2. [è¯·æ±‚å¤„ç†æµç¨‹](#è¯·æ±‚å¤„ç†æµç¨‹)
3. [æ•æ„Ÿè¯æ£€æµ‹æµç¨‹](#æ•æ„Ÿè¯æ£€æµ‹æµç¨‹)
4. [APIè°ƒç”¨æµç¨‹](#apiè°ƒç”¨æµç¨‹)
5. [é”™è¯¯å¤„ç†æµç¨‹](#é”™è¯¯å¤„ç†æµç¨‹)
6. [æ—¥å¿—è®°å½•æµç¨‹](#æ—¥å¿—è®°å½•æµç¨‹)

## ğŸš€ ç³»ç»Ÿå¯åŠ¨æµç¨‹

### å¯åŠ¨æ—¶åºå›¾
```
ç”¨æˆ· -> main.py -> LLMGuardSystem -> é…ç½®ç®¡ç†å™¨ -> æ•æ„Ÿè¯æ£€æµ‹å™¨ -> APIå®¢æˆ·ç«¯ -> å°±ç»ªçŠ¶æ€
```

### è¯¦ç»†å¯åŠ¨æ­¥éª¤

#### 1. ç¨‹åºå…¥å£ (main.py)
```python
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser()
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = LLMGuardSystem(args.config)
```

#### 2. ç³»ç»Ÿåˆå§‹åŒ– (LLMGuardSystem.__init__)
```python
def __init__(self, config_file: str = "config.json"):
    # æ­¥éª¤1: åŠ è½½é…ç½®æ–‡ä»¶
    self.config = self._load_config(config_file)
    
    # æ­¥éª¤2: åˆå§‹åŒ–æ•æ„Ÿè¯æ£€æµ‹å™¨
    detector_config = self.config.get("sensitive_detector", {})
    self.sensitive_detector = create_detector(detector_config)
    
    # æ­¥éª¤3: åˆå§‹åŒ–APIå®¢æˆ·ç«¯
    api_config = self.config.get("api_client", {})
    self.api_client = create_api_client(api_config)
    
    # æ­¥éª¤4: åˆå§‹åŒ–å®‰å…¨å®¢æˆ·ç«¯
    self.safe_client = SafeLLMClient(self.api_client, self.sensitive_detector)
```

#### 3. é…ç½®åŠ è½½è¿‡ç¨‹
```python
def _load_config(self, config_file: str) -> Dict[str, Any]:
    # é»˜è®¤é…ç½®
    default_config = {...}
    
    # å¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œåˆå¹¶ç”¨æˆ·é…ç½®
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            user_config = json.load(f)
        # é€’å½’åˆå¹¶é…ç½®
        merge_config(default_config, user_config)
    
    return default_config
```

#### 4. æ•æ„Ÿè¯æ£€æµ‹å™¨åˆå§‹åŒ–
```python
def __init__(self, sensitive_words_file="sensitive_words.txt", ...):
    # åŠ è½½æ•æ„Ÿè¯åˆ—è¡¨
    self.sensitive_words = self._load_sensitive_words()
    
    # åˆå§‹åŒ–llm-guardçš„BanSubstringsæ‰«æå™¨
    self.scanner = BanSubstrings(
        substrings=self.sensitive_words,
        match_type=self.match_type,
        case_sensitive=self.case_sensitive,
        redact=self.redact,
        contains_all=self.contains_all
    )
```

#### 5. APIå®¢æˆ·ç«¯åˆå§‹åŒ–
```python
def __init__(self, api_key, base_url, model, ...):
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹é€šä¹‰åƒé—®ï¼‰
    self.client = OpenAI(
        api_key=self.api_key,
        base_url=self.base_url
    )
```

## ğŸ”„ è¯·æ±‚å¤„ç†æµç¨‹

### ä¸»è¦å¤„ç†å‡½æ•°
```python
def process_request(self, user_input: str, system_prompt: Optional[str] = None) -> Dict[str, Any]:
```

### å¤„ç†æµç¨‹å›¾
```
ç”¨æˆ·è¾“å…¥ 
    â†“
[1] å¼€å§‹è®¡æ—¶
    â†“
[2] è·å–å®‰å…¨é…ç½®
    â†“
[3] è°ƒç”¨å®‰å…¨å®¢æˆ·ç«¯
    â†“
[4] è¾“å…¥å®‰å…¨æ£€æŸ¥
    â†“
[5] APIè°ƒç”¨ (å¦‚æœè¾“å…¥å®‰å…¨)
    â†“
[6] è¾“å‡ºå®‰å…¨æ£€æŸ¥
    â†“
[7] ç”Ÿæˆç»“æœå¯¹è±¡
    â†“
[8] è®°å½•æ—¥å¿—
    â†“
[9] è¿”å›ç»“æœ
```

### è¯¦ç»†æ­¥éª¤å®ç°

#### æ­¥éª¤1-2: åˆå§‹åŒ–å’Œé…ç½®
```python
def process_request(self, user_input: str, system_prompt: Optional[str] = None):
    start_time = datetime.now()  # å¼€å§‹è®¡æ—¶
    
    # è·å–å®‰å…¨é…ç½®
    safety_config = self.config.get("safety", {})
    check_input = safety_config.get("check_input", True)
    check_output = safety_config.get("check_output", True)
    log_blocked = safety_config.get("log_blocked_requests", True)
```

#### æ­¥éª¤3: è°ƒç”¨å®‰å…¨å®¢æˆ·ç«¯
```python
    # è°ƒç”¨å®‰å…¨å®¢æˆ·ç«¯è¿›è¡Œå¤„ç†
    result = self.safe_client.safe_chat(
        user_message=user_input,
        system_message=system_prompt,
        check_input=check_input,
        check_output=check_output
    )
```

#### æ­¥éª¤4-9: åå¤„ç†å’Œè¿”å›
```python
    # æ·»åŠ å¤„ç†æ—¶é—´å’Œæ—¶é—´æˆ³
    end_time = datetime.now()
    result["processing_time"] = (end_time - start_time).total_seconds()
    result["timestamp"] = end_time.isoformat()
    
    # è®°å½•è¢«é˜»æ­¢çš„è¯·æ±‚
    if result.get("blocked") and log_blocked:
        self._log_blocked_request(user_input, result)
    
    return result
```

## ğŸ” æ•æ„Ÿè¯æ£€æµ‹æµç¨‹

### æ£€æµ‹å‡½æ•°
```python
def scan(self, text: str) -> Tuple[str, bool, float]:
```

### æ£€æµ‹æµç¨‹å›¾
```
è¾“å…¥æ–‡æœ¬
    â†“
[1] æ–‡æœ¬é¢„å¤„ç†
    â†“
[2] BanSubstringsæ‰«æ
    â†“
[3] åŒ¹é…ç»“æœåˆ†æ
    â†“
[4] é£é™©è¯„åˆ†è®¡ç®—
    â†“
[5] å†…å®¹æ›¿æ¢ (å¦‚æœéœ€è¦)
    â†“
[6] è¿”å›ç»“æœ
```

### è¯¦ç»†å®ç°

#### BanSubstringsæ‰«æè¿‡ç¨‹
```python
def scan(self, text: str) -> Tuple[str, bool, float]:
    if not text:
        return text, True, 0.0
    
    try:
        # è°ƒç”¨llm-guardçš„æ‰«æå™¨
        sanitized_text, is_valid, risk_score = self.scanner.scan(text)
        
        if not is_valid:
            logger.warning(f"æ£€æµ‹åˆ°æ•æ„Ÿè¯ï¼Œé£é™©è¯„åˆ†: {risk_score}")
            logger.debug(f"åŸæ–‡æœ¬: {text[:100]}...")
            logger.debug(f"å¤„ç†å: {sanitized_text[:100]}...")
        
        return sanitized_text, is_valid, risk_score
        
    except Exception as e:
        logger.error(f"æ•æ„Ÿè¯æ‰«æå¤±è´¥: {e}")
        return text, False, 1.0
```

#### é£é™©è¯„åˆ†æœºåˆ¶
```python
# llm-guardå†…éƒ¨çš„è¯„åˆ†é€»è¾‘
if æ£€æµ‹åˆ°æ•æ„Ÿè¯:
    risk_score = 1.0    # é«˜é£é™©
    is_valid = False    # ä¸å®‰å…¨
else:
    risk_score = -1.0   # å®‰å…¨
    is_valid = True     # å®‰å…¨
```

#### å†…å®¹æ›¿æ¢æœºåˆ¶
```python
# å½“redact=Trueæ—¶ï¼Œæ•æ„Ÿè¯ä¼šè¢«æ›¿æ¢
åŸæ–‡: "è¿™ä¸ªå†…å®¹åŒ…å«æ•æ„Ÿè¯æ±‡"
å¤„ç†å: "è¿™ä¸ªå†…å®¹åŒ…å«[REDACT]"
```

## ğŸŒ APIè°ƒç”¨æµç¨‹

### å®‰å…¨å®¢æˆ·ç«¯å¤„ç†
```python
def safe_chat(self, user_message: str, system_message: Optional[str] = None,
              check_input: bool = True, check_output: bool = True) -> Dict[str, Any]:
```

### APIè°ƒç”¨æµç¨‹å›¾
```
ç”¨æˆ·æ¶ˆæ¯
    â†“
[1] åˆå§‹åŒ–ç»“æœå¯¹è±¡
    â†“
[2] è¾“å…¥å®‰å…¨æ£€æŸ¥ (å¯é€‰)
    â†“
[3] æ£€æŸ¥æ˜¯å¦è¢«é˜»æ­¢
    â†“
[4] è°ƒç”¨LLM API
    â†“
[5] è¾“å‡ºå®‰å…¨æ£€æŸ¥ (å¯é€‰)
    â†“
[6] æœ€ç»ˆç»“æœå¤„ç†
    â†“
è¿”å›ç»“æœå¯¹è±¡
```

### è¯¦ç»†å®ç°

#### æ­¥éª¤1: åˆå§‹åŒ–ç»“æœå¯¹è±¡
```python
result = {
    "original_input": user_message,
    "input_safe": True,
    "input_risk_score": 0.0,
    "sanitized_input": user_message,
    "response": "",
    "output_safe": True,
    "output_risk_score": 0.0,
    "sanitized_output": "",
    "blocked": False,
    "block_reason": ""
}
```

#### æ­¥éª¤2: è¾“å…¥å®‰å…¨æ£€æŸ¥
```python
if check_input and self.sensitive_detector:
    sanitized_input, input_safe, input_risk = self.sensitive_detector.scan(user_message)
    result.update({
        "input_safe": input_safe,
        "input_risk_score": input_risk,
        "sanitized_input": sanitized_input
    })
    
    if not input_safe:
        result.update({
            "blocked": True,
            "block_reason": "è¾“å…¥åŒ…å«æ•æ„Ÿè¯",
            "response": "æŠ±æ­‰ï¼Œæ‚¨çš„è¾“å…¥åŒ…å«ä¸å½“å†…å®¹ï¼Œæ— æ³•å¤„ç†ã€‚"
        })
        return result
```

#### æ­¥éª¤4: LLM APIè°ƒç”¨
```python
try:
    response = self.api_client.simple_chat(user_message, system_message)
    result["response"] = response
except Exception as e:
    result.update({
        "blocked": True,
        "block_reason": f"APIè°ƒç”¨å¤±è´¥: {str(e)}",
        "response": "æŠ±æ­‰ï¼ŒæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    })
```

#### æ­¥éª¤5: è¾“å‡ºå®‰å…¨æ£€æŸ¥
```python
if check_output and self.sensitive_detector:
    sanitized_output, output_safe, output_risk = self.sensitive_detector.scan(response)
    result.update({
        "output_safe": output_safe,
        "output_risk_score": output_risk,
        "sanitized_output": sanitized_output
    })
    
    if not output_safe:
        result.update({
            "blocked": True,
            "block_reason": "è¾“å‡ºåŒ…å«æ•æ„Ÿè¯",
            "response": "æŠ±æ­‰ï¼Œæ¨¡å‹ç”Ÿæˆçš„å†…å®¹åŒ…å«ä¸å½“ä¿¡æ¯ï¼Œå·²è¢«è¿‡æ»¤ã€‚",
            "sanitized_output": sanitized_output
        })
```

## âŒ é”™è¯¯å¤„ç†æµç¨‹

### é”™è¯¯ç±»å‹å’Œå¤„ç†ç­–ç•¥

#### 1. é…ç½®æ–‡ä»¶é”™è¯¯
```python
try:
    with open(config_file, 'r', encoding='utf-8') as f:
        user_config = json.load(f)
except FileNotFoundError:
    logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    user_config = {}
except json.JSONDecodeError as e:
    logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
    user_config = {}
```

#### 2. æ•æ„Ÿè¯æ–‡ä»¶é”™è¯¯
```python
try:
    with open(self.sensitive_words_file, 'r', encoding='utf-8') as f:
        words = [line.strip() for line in f if line.strip()]
except FileNotFoundError:
    logger.error(f"æ•æ„Ÿè¯æ–‡ä»¶ä¸å­˜åœ¨: {self.sensitive_words_file}")
    return []
except UnicodeDecodeError as e:
    logger.error(f"æ•æ„Ÿè¯æ–‡ä»¶ç¼–ç é”™è¯¯: {e}")
    return []
```

#### 3. APIè°ƒç”¨é”™è¯¯
```python
try:
    response = self.client.chat.completions.create(**params)
except openai.APIError as e:
    logger.error(f"APIé”™è¯¯: {e}")
    raise
except openai.RateLimitError as e:
    logger.warning(f"APIé™æµ: {e}")
    time.sleep(1)  # ç­‰å¾…åé‡è¯•
    raise
except Exception as e:
    logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
    raise
```

#### 4. æ•æ„Ÿè¯æ£€æµ‹é”™è¯¯
```python
try:
    sanitized_text, is_valid, risk_score = self.scanner.scan(text)
    return sanitized_text, is_valid, risk_score
except Exception as e:
    logger.error(f"æ•æ„Ÿè¯æ‰«æå¤±è´¥: {e}")
    # å®‰å…¨ä¼˜å…ˆï¼šæ£€æµ‹å¤±è´¥æ—¶è®¤ä¸ºä¸å®‰å…¨
    return text, False, 1.0
```

## ğŸ“ æ—¥å¿—è®°å½•æµç¨‹

### æ—¥å¿—é…ç½®
```python
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('llm_guard.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
```

### æ—¥å¿—è®°å½•ç‚¹

#### 1. ç³»ç»Ÿå¯åŠ¨æ—¥å¿—
```python
logger.info("LLMå®‰å…¨é˜²æŠ¤ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
logger.info(f"åŠ è½½äº† {len(self.sensitive_words)} ä¸ªæ•æ„Ÿè¯")
logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.model}")
```

#### 2. è¯·æ±‚å¤„ç†æ—¥å¿—
```python
logger.info(f"å¤„ç†ç”¨æˆ·è¯·æ±‚: {user_input[:50]}...")
logger.info(f"APIè°ƒç”¨æˆåŠŸï¼Œä½¿ç”¨token: {total_tokens}")
```

#### 3. å®‰å…¨äº‹ä»¶æ—¥å¿—
```python
logger.warning(f"æ£€æµ‹åˆ°æ•æ„Ÿè¯ï¼Œé£é™©è¯„åˆ†: {risk_score}")
logger.warning(f"è¯·æ±‚è¢«é˜»æ­¢: {block_reason}")
```

#### 4. é”™è¯¯æ—¥å¿—
```python
logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
logger.error(f"æ•æ„Ÿè¯æ‰«æå¤±è´¥: {e}")
```

### è¢«é˜»æ­¢è¯·æ±‚çš„è¯¦ç»†æ—¥å¿—
```python
def _log_blocked_request(self, user_input: str, result: Dict[str, Any]):
    log_entry = {
        "timestamp": result["timestamp"],
        "user_input": user_input[:100] + "..." if len(user_input) > 100 else user_input,
        "block_reason": result["block_reason"],
        "input_risk_score": result.get("input_risk_score", 0),
        "output_risk_score": result.get("output_risk_score", 0)
    }
    
    logger.warning(f"è¯·æ±‚è¢«é˜»æ­¢: {json.dumps(log_entry, ensure_ascii=False)}")
```

---

é€šè¿‡è¿™ä¸ªè¯¦ç»†çš„å·¥ä½œæµç¨‹æ–‡æ¡£ï¼Œæ‚¨å¯ä»¥æ¸…æ¥šåœ°äº†è§£ç³»ç»Ÿçš„æ¯ä¸ªç¯èŠ‚æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥åŠå„ä¸ªç»„ä»¶ä¹‹é—´æ˜¯å¦‚ä½•åè°ƒé…åˆçš„ã€‚è¿™ä¸ªç³»ç»Ÿé‡‡ç”¨äº†å¤šå±‚é˜²æŠ¤ã€é”™è¯¯å®‰å…¨ä¼˜å…ˆçš„è®¾è®¡ç†å¿µï¼Œç¡®ä¿åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½èƒ½æä¾›å¯é çš„å®‰å…¨é˜²æŠ¤ã€‚
